#!/usr/bin/env python3

import os, sys, csv, json, re, datetime
from argparse import ArgumentParser
import xml.etree.ElementTree as et
import csv, codecs
import urllib.request as urllib2
from collections import namedtuple
from multiprocessing import Pool, set_start_method
import sldr.langtags_full as lt
from palaso.unicode.ucd import UCD

silns = "urn://www.sil.org/ldml/0.1"
apiversion = "1.4"

hacks = {
    "aeb-Arab-TN": (lambda n:n['tags'].extend(("aeb-Arab-IL", "ar-aeb-Arab-IL")), lambda n:n['regions'].remove('IL')),
#    "aeb-Hebr-IL": (lambda n:n['tags'].extend(("ar-aeb-Hebr", "ar-aeb-Hebr-IL")),),
#    "aeb-Latn-TN": (lambda n:n.setdefault('tags', []).extend(("ar-aeb-Latn", "ar-aeb-Latn-TN")),)
}

Autonym = namedtuple('Autonym', ['langtag', 'name', 'roman'])
ucds = UCD()

def reciter(base, fn, i=0):
    n = fn(base)
    if n is None:
        return
    if i > 10:      # poor man's loop detector

        return
    for a in n:
        yield a
        yield from reciter(a, fn, i+1)

def read_autonyms(filename):
    def stripinvisibles(s):
        return re.sub("[\u200E]", "", s)
    res = {}
    with open(filename) as inf:
        rdr = csv.reader(inf)
        next(rdr)
        for row in rdr:
            lang = row[0].strip()
            name = row[2].strip()
            if len(row) > 4:
                roman = row[4].strip()
            # handle missing comma after T
            elif len(row) > 3 and row[3].startswith("T"):
                roman = row[3][1:].strip()
            else:
                roman = ""
            script = script_analyze(name)
            lt = "{}-{}".format(lang, script)
            a = Autonym(lt, stripinvisibles(name), stripinvisibles(roman))
            res.setdefault(lt, []).append(a)
    return res

def script_analyze(s):
    res = {}
    for c in s:
        for sc in ucds.get(ord(c), 'scx').split():
            if not sc.startswith('Z'):
                res[sc] = res.setdefault(sc, 0) + 1
    return sorted(res.keys(), key=lambda x:-res[x])[0]

def find_file(tagstr, root='.', alt='.') :
    fname = tagstr.replace('-', '_') + '.xml'
    for a in (root, alt, '.'):
        for f in (fname, os.path.join(fname[0], fname)):
            testf = os.path.join(a, f)
            if os.path.exists(testf):
                return testf
    return None

def getlocalename(testf, getnames):
    try:
        doc = et.parse(testf)
    except:
        return None
    if len(doc.getroot()) > 1 :
        for getname in getnames:
            if getname is None:
                print(getnames)
                continue
            bits = getname.split("-")
            for i in range(len(bits), 0, -1):
                e = doc.find('./localeDisplayNames/languages/language[@type="{}"]'.format("_".join(bits[0:i])))
                if e is not None:
                    return e.text
    return None

def issimple(testf):
    try:
        doc = et.parse(testf)
    except:
        return False
    root = doc.getroot()
    if len(root) < 2:
        return True
    elif len(root) > 2:
        return False
    elif root[-1].tag == "special" and all(x.tag.startswith(f"{{{silns}}}") for x in root[-1]):
        return True
    return False

def process_cldrentry(s, lts, allentries, root='.'):
    s = s.replace("_", "-")
    if s in lts:
        return
    l = lt.LangTag(s)
    if l.variants is not None and 'posix' in l.variants:
        return
    l.parentsame = False
    n = None
    if l.region is not None:
        t = lt.LangTag(tag=None, lang=l.lang, script=l.script, variants=l.variants, extensions=l.extensions)
        if str(t) in lts:
            n = lts[str(t)]
        elif str(t) in allentries:
            if str(l.region) in allentries[str(t)][1]:
                n = allentries[str(t)][0]
        if n is not None:
            if l.script is None:
                l.script = n.script
            assert l.lang is not None
            if n.hidescript and l.lang+"-"+l.region not in lts:
                l.hidescript = True
            l.extra_variants = n.extra_variants
        testf = find_file(str(t), root=root)
        if testf is not None:
            l.parent = t
            l.parentsame = issimple(find_file(s, root))
    if not l.parentsame:
        lts.add(l)
    elif n is None or l.region not in n.regions:
        print(f"LDML region for {l} not in regions list")
    return l

def addnames(n, b, names, regions, getname=True):
    alllrefs = set()
    regionlist = [b.region] + sorted(list(set(r for r in getattr(b, 'regions', []) if r != b.region)))
    for reg in regionlist:
        if reg is not None:
            regions.add(reg)
        lname = "{}-{}".format(getattr(b, 'iso639', b.lang), reg)
        alllrefs.add(lname)
        if lname in names:
            if 'name' in n or not getname:
                n['names'].append(names[lname][0][0])
            else:
                n['name'] = names[lname][0][0]
            n['names'].extend(names[lname][1])
    return alllrefs

def get_region_scriptnames():
    regs = {}
    scripts = {}
    fname = os.path.join(os.path.dirname(lt.__file__), "language-subtag-registry.txt")
    with open(fname) as f :
        currlang = None
        currname = None
        currscr = None
        mode = None
        deprecated = False
        for l in f.readlines() :
            l = l.strip()
            if l.startswith("Type: ") :
                mode = l[6:]
                if currlang is not None and currname is not None:
                    regs[currlang] = currname
                elif currscr is not None and currname is not None:
                    scripts[currscr] = currname
                currlang = None
                currscr = None
                currname = None
            elif l.startswith("Subtag: ") :
                if mode == "region":
                    currlang = l[8:]
                elif mode == "script":
                    currscr = l[8:]
            elif l.startswith("Description: "):
                if mode in ("region", "script"):
                    currname = l[13:]
        if currlang is not None:
            regs[currlang] = currname
        elif currscr is not None:
            scripts[currscr] = currname
    regs['TW'] = 'China-Taiwan'  # A tricky political choice
    regs['XK'] = 'Kosovo'   # a private tag that is in use by CLDR as of 2025
    return regs, scripts

def fromiso639(t, isomap):
    b = t.split("-")
    b[0] = isomap.get(b[0], b[0])
    return "-".join(b)

def make_record(t, args):
    if t.skip:
        return None
    r = t.allforms()
    if not len(r[0]):
        return None
    if r[0][0] == "q" and r[0][1] in "abcdefghijklmnopqrst":
        return None
    if t.region is None:
        print("Missing Region for {}".format(str(t)))
        return None
    if hasattr(t, 'primary'):
        r = [t.primary] + [x for x in r if x != t.primary]
    # Add an entry for the region (if region hidden and this is the only tagset for this region in this lang)
    if t.hideregion and not t.hidescript:
        x = lt.LangTag(lang=t.lang, region=t.region, variants=t.variants, extensions=t.extensions)
        if len(allregions.get(str(x), [])) < 2:
            r.insert(1, str(x))
    # Add an entry for the script (if script hidden and this is the only tagset for this script in this lang)
    elif t.hidescript and not t.hideregion:
        x = lt.LangTag(lang=t.lang, script=t.script, variants=t.variants, extensions=t.extensions)
        if len(allscripts.get(str(x), [])) < 2:
            r.insert(1, str(x))
    # Fixup for Windows getting confused by reserved device names in DOS
    if r[0] in ('con', 'prn', 'aux', 'nul'):
        ts = f"{r[0]}-Arab" if r[0] == "prn" else f"{r[0]}-Latn"
        if ts in r:
            r.remove(ts)
        r.insert(0, ts)
    n = {'tag': r[0], 'full': r[-1], 'script': t.script, 'region': t.region}
    wintag = t.copy()
    if suppress.get(str(t), '') == t.script:
        n['suppress'] = True
        wintag.hidescript = True
    else:
        wintag.hidescript = False
    if len(langregions.get(t.lang, [])) > 1:
#        if t.lang.startswith("a"):
#            print(f"{t.lang}: {langregions[t.lang]}")
        wintag.hideregion = False
    n['windows'] = str(wintag)
    if t.region in regionnames:
        n['regionname'] = regionnames[t.region]
    tags = set(str(t) for t in r[1:-1])
    hassldr = False
    # n['primary'] = True
    if False and "-x-" in n['tag']:
        stripx = n['tag'].find("-x-")
        s = n['tag'][:stripx] if stripx >=0 else n['tag']
        finald = s.rfind("-")
        if finald >= 0:
            test = s[:finald]
            testl = lts.get(test, None)
            if testl is not None and testl != t:
                n['primary'] = False

    # A hack to resolve ICU's used of zh and industry use of zh-CN
    # Code positioned here to use zh when hunting localname
    if r[0] == 'zh':
        n['tag'] = 'zh-CN'
        tags.discard('zh-CN')
        tags.add("zh")
    for a in [n['tag'], n['full']] + list(tags):
        atag = lt.LangTag(a)
        al = atag.lang
        if al not in preferences:
            continue
        for ap in preferences[al]:
            ntag = lt.LangTag(a)
            apt = lt.LangTag(ap)
            if apt.script is not None:
                if t.script != apt.script:
                    continue
                ntag.script = apt.script
            elif ntag.script is not None and apt.script is not None and ntag.script != apt.script:
                continue
            if apt.region is not None:
                if apt.region != t.region:
                    continue
                ntag.region = apt.region
            ntag.lang = apt.lang
            tags.add(str(ntag))
    if len(tags):
        n['tags'] = sorted(tags)
    if "-" in r[0]:
        ismin = lts.get(t.lang, None) is None or t.lang in ("con", "prn")
    else:
        ismin = True
    if hasattr(t, 'iso639') and ismin:
        n['iso639_3'] = t.iso639
    if t.base is not None and len(t.base):
        for b in reciter(t, lambda x:getattr(x, 'base', None)):
            # we must have an iso639_3 or else the base must just be a language. emk has no simple language form
            if n.get('iso639_3', None) is None and "-" in b.allforms()[0] and b.allforms()[0][:3] not in ("emk", ):
                continue
            bi = getattr(b, 'iso639', None)
            if bi is None or bi == n.get('iso639_3', None):
                continue
            n.setdefault('iso639_3extra', set()).add(bi)
    #elif not hasattr(t, 'iso639') and t.lang in lts:
    #    x = lts[t.lang]
    #    if hasattr(x, 'iso639'):
    #        n['iso639_3'] = x.iso639
    if 'iso639_3' in n:
        macro = macros.get(n['iso639_3'], None)
        if macro is not None:
            n['macrolang'] = iso639map.get(macro, macro)
        contains = macrocontains.get(n['iso639_3'], None)
        if contains is not None:
            n['contains'] = [iso639map.get(c, c) for c in contains]
    auto = set()
    for l in r:
        x = lt.LangTag(l)
        # Pending a need:
        # if str(x) in cldrs:
        #     n['fromCldr'] = True
        if not x.script:
            continue
        s = "{}-{}".format(x.lang, x.script)
        if s in autonyms:
            auto.update(autonyms[s])
        if 'iso639_3' in n:
            s = "{}-{}".format(n['iso639_3'], x.script)
            if s in autonyms:
                auto.update(autonyms[s])
    if len(auto):
        lauto = sorted(auto)
        n['localnames'] = [a.name for a in lauto]
        n['latnnames'] = [a.roman for a in lauto]
        if not any(n['latnnames']):
            del n['latnnames']
    for rf in r:
        tf = find_file(rf, root=args.flatdir, alt=args.indir)
        if tf is not None:
            hassldr = True
            getnames = [n['full']]
            if len(r) > 2:
                getnames.extend(n['tags'])
            getnames.extend([n['tag'], t.lang])
            name = getlocalename(tf, getnames)
            if name is not None and name != "" and 'localname' not in n:
                n['localname'] = name
    n['sldr'] = hassldr
    n['names'] = []
    regions = set()
    alllrefs = addnames(n, t, names, regions)
    for b in t.base:
        alllrefs.update(addnames(n, b, names, regions, getname=False))
    if t.lang in iananames:
        extlang = "-".join([t.lang] + t._extensions())
        ns = iananames.get(extlang, getattr(t, 'name', iananames[t.lang]))[:]
        if len(ns):
            if 'name' not in n:
                n['name'] = ns[0]
            n['iana'] = ns
            if len(ns) > 0 :
                n['names'].extend(ns)
    if 'name' in n:
        n['names'] = sorted(x for x in set(n['names']) - set([n['name']]) if len(x))
        n['names'] = [x for x in n['names'] if x.lower() not in pejoratives.get(n.get('iso639_3', t.lang)+"-"+t.region, [])]
    elif hasattr(t, 'name'):
        n['name'] = t.name[0]
    else:
        print("Missing name entry for {} = {}".format(n['tag'], n['full']))
    if not len(n['names']):
        del n['names']
    if not len(n.get('iso639_3', "fred")):
        del n['iso639_3']
    if t.region is not None:
        regions.discard(t.region)
    regions.discard('XX')
    if (args.hack & 1) == 1:
        regions.discard("XK")
    testtag = re.sub(r'-(?:[A-Z]{2}|\d{3})(?:-|$)', '-{}', n['full'])
    regions = [r for r in regions if testtag.format(r) not in lts]
    if len(regions):
        n['regions'] = sorted(regions)
#            n['regions'] = " ".join(sorted(regions))
    if getattr(t, 'nofonipa', False):
        n['nophonvars'] = True
    if getattr(t, 'extra_variants', ""):
        n['variants'] = t.extra_variants
    if getattr(t, 'svariants', None):
        n['svariants'] = t.svariants
    if getattr(t, 'rod', ""):
        n['rod'] = t.rod
    if getattr(t, 'obsolete', False):
        n['obsolete'] = True
    if getattr(t, 'unwritten', False):
        n['unwritten'] = True
    if n['full'] in hacks:
        for c in hacks[n['full']]:
            c(n)

    if n['tag'] in collisions:
        print("Multiple entries for: {} = {}, {}".format(n['tag'], n['full'], collisions[n['tag']]))
    else:
        collisions[n['tag']] = n['full']
    for k, v in n.items():
        if v is None:
            print("Null entry for {} in {}".format(k, n['tag']))
    if 'iso639_3extra' in n:
        n['iso639_3extra'] = sorted(n['iso639_3extra'])
    return n, alllrefs

def main():
    parser = ArgumentParser()
    parser.add_argument('infile', help='Input CSV file from Google drive')
    parser.add_argument('outfile', help='alltags.txt output file')
    parser.add_argument('-f','--flatdir', default='.', help='Directory containing full sldr tree, for language names')
    parser.add_argument('-i','--indir', default='.', help='Directory containing sldr tree with inheritance')
    parser.add_argument('-p','--operators',action="store_true",default=False,help="Output complex operators")
    parser.add_argument('-L','--langindex',help="Use local LanguageInfo.tab")
    parser.add_argument('-M','--macros',help="Use ISO639-3 Macrolanguage mappings file")
    parser.add_argument('-a','--autonyms',help="CSV of Autonyms from Ethnologue")
    parser.add_argument('-q','--quiet',action='store_false',default=True,help='Be noisy')
    parser.add_argument('-j','--jobs',type=int,default=0,help='Number of parallel jobs to run, 0 = number of processors')
    parser.add_argument('-Z','--debug',help="Break inside for the given lang tag prefix")
    parser.add_argument('-H','--hack',type=int,default=0,help='bitmap of hacks 1 - strip XK from regions list')
    args = parser.parse_args()

    if args.debug is not None:
        args.jobs = 1

    if args.flatdir and not os.path.exists(args.flatdir):
        print(f"Can't find {args.flatdir}")

    global iananames, iso639map, lts, preferences, regionnames, suppress
    cldrs = {}
    deprecated = {}
    iananames = {}
    lts = lt.LangTags(noalltags=True)
    preferences = {}
    suppress = {}
    for k,v in lts.items():
        if getattr(v, 'deprecated', False):
            deprecated[v.lang] = "1"
        if hasattr(v, 'desc'):
            iananames[k] = v.desc
        if getattr(v, 'suppress', False):
            suppress[k] = v.script
        if getattr(v, 'isCldr', False):
            cldrs[k] = True
        pref = getattr(v, 'preferred', None)
        if pref is not None and v.mode == "extlang":
            preferences.setdefault(pref, []).append(k)
    regionnames, scriptnames = get_region_scriptnames()
    lts.clear()
    allentries = {}
    allmacros = {}
    iso639map = {}
    if not args.quiet:
        print("Reading CSV")
    with open(args.infile) as csvfile :
        reader = csv.DictReader(csvfile)
        for row in reader :
    #        if 'CLDR' in row['confirmed'] : continue
            lid = row['Lang_Id']
            ls = row['likely_subtag']
            i6 = row['ISO 639-3']
            d = row['deprecated']
            rod = row['ROD']
            variants = row['variants'].split()
            svariants = row['svariants'].split()
            macro = row['Macro']
            t = lt.LangTag(ls)
            b = lt.LangTag(lid)
            if b.lang == "000":
                continue
            if args.debug is not None and str(b).startswith(args.debug):
                import pdb; pdb.set_trace()
            if d != "":
                deprecated[t.lang] = d
                if (4 > len(d) > 1 or "-" in d) and macro == "":
                    macro = d
            if b.script in [None, 'Zyyy', 'Qaax']:
                t.hidescript = True
            if b.region is None :
                t.hideregion = True
            t.hideboth |= (t.hideregion and t.hidescript)
            if b.variants is None and t.variants is not None:
                t.hidevariants = t.variants[:]
            if b.extensions is None and t.extensions is not None:
                t.hideextensions = {k: v[:] for k, v in t.extensions.items()}
            if t.lang in deprecated:
                t.deprecated = deprecated[t.lang]
            t.regions = row['regions'].split()
            t.name = [row['LangName']]
            t = lts.add(t)
            if repr(t) in lts:
                lts[repr(t)].iso639 = i6
            if i6 != t.lang:
                iso639map[i6] = t.lang
            allentries[lid] = (t, row['regions'].split(' '))
            if macro != "":
                s = str(t)
                m = lt.LangTag(macro)
                if macro in t.allforms():
                    t.primary = macro
                else:
                    m.merge_equivalent(t)
                allmacros[s] = repr(m)
            t.nofonipa = not t.hidescript and t.script != 'Latn'
            t.extra_variants = variants
            t.rod = rod
            t.obsolete = row['obsolete'] != ""
            t.unwritten = row['unwritten'] != ""
            t.svariants = svariants

    if not args.quiet:
        print("Reading sldr")
    for l in os.listdir(args.indir) :
        if l.endswith('.xml') :
            if 1 < len(l.split('_', 1)[0]) < 4 :
                process_cldrentry(l[:-4], lts, allentries, root=args.indir)
        elif len(l) == 1 and os.path.isdir(os.path.join(args.indir, l)) :
            for s in os.listdir(os.path.join(args.indir, l)) :
                if s.endswith('.xml') :
                    if 1 < len(s.split('_', 1)[0]) < 4 :
                        process_cldrentry(s[:-4], lts, allentries, root=args.indir)

    for k, v in allmacros.items():
        base = lts[k]
        try:
            macro = lts[v]
        except KeyError:
            macro = lt.LangTag(v)
            lts.add(macro)
            macro.iso639 = base.iso639
            if base.script is None:
                macro.hidescript = True
            if base.region is None:
                macro.hideregion = True
        if base != macro:
            base.skip = True
        if not hasattr(macro, 'regions'):
            macro.regions = []
        if hasattr(base, 'regions'):
            macro.regions.extend(base.regions)
        for a in ('extra_variants', 'svariants'):
            ev = getattr(base, a, [])
            if len(ev):
                setattr(macro, a, sorted(set(getattr(macro, a, []) + ev)))
        assert macro.base is not None
        macro.base.append(base)

    global names, pejoratives
    names = {}
    pejoratives = {}
    if args.langindex:
        namef = open(args.langindex, "r")
    else:
        req = urllib2.Request(url="https://www.ethnologue.com/codes/LanguageIndex.tab",
                            headers = {"User-Agent": "Mozilla"})
        namef = urllib2.urlopen(req)
    reader = csv.DictReader(namef, dialect=csv.excel_tab)
    for r in reader:
        if r['CountryID'] == 'ET' and r['NameType'] == 'LA':     # hack fix for buggy Ethnologue data. To Be Reviewed 21/Feb/2019, 2020
            pejoratives.setdefault(r['LangID']+"-"+r['CountryID'], []).append(r['Name'].lower())
        elif r['NameType'].startswith("L") and r['CountryID'] and not r['NameType'].endswith("P"):
            names.setdefault(r['LangID']+"-"+r['CountryID'], [[],[]])[0 if r['NameType'] == 'L' else 1].append(r['Name'])
        elif r['NameType'] == 'LP' and r['CountryID']:
            pejoratives.setdefault(r['LangID']+"-"+r['CountryID'], []).append(r['Name'].lower())
    namef.close()

    global macrocontains, macros
    macros = {}
    macrocontains = {}
    if args.macros:
        namef = open(args.macros, "rb")
    else:
        req = urllib2.Request(url="https://iso639-3.sil.org/sites/iso639-3/files/downloads/iso-639-3-macrolanguages.tab",
                                headers = {"User-Agent": "Mozilla"})
        namef = urllib2.urlopen(req)
    fields = namef.readline().decode("utf-8").split("\t")
    for l in namef.readlines():
        b = l.decode("utf-8").strip().split("\t")
        r = {fields[i]: b[i] for i in range(len(fields))}
        macros[r['I_Id']] = r['M_Id']
        macrocontains.setdefault(r['M_Id'], []).append(r['I_Id'])
    namef.close()

    global allregions, allscripts, collisions, langregions
    collisions = {}
    res = []
    alllangreg = set()
    allscripts = {}
    allregions = {}
    langregions = {}
    usedregions = set()
    usedscripts = set()

    for t in set(lts.values()):
        x = lt.LangTag(lang=t.lang, region=t.region, variants=t.variants, extensions=t.extensions)
        allregions.setdefault(str(x), set()).add(t)
        usedregions.add(t.region)
        usedscripts.add(t.script)
        y = t.copy()
        #y.hidescript = True
        #y.hideboth = True
        y.hideregion = True
        langregions.setdefault(str(y), set()).add(t.region)
        x = lt.LangTag(lang=t.lang, script=t.script, variants=t.variants, extensions=t.extensions)
        allscripts.setdefault(str(x), set()).add(t)

    global autonyms
    if args.autonyms:
        autonyms = read_autonyms(args.autonyms)
    else:
        autonyms = {}

    if not args.quiet:
        print("Making records")
    # special record for passing standard variants
    conformance: dict[str, str|list]= {'tag': "_conformance"}
    extrascripts = set((x for x in scriptnames.keys() if len(x) == 4))
    extrascripts.update(('Qaa'+chr(97+a) for a in range(26)))
    extrascripts.update(('Qab'+chr(97+a) for a in range(24)))
    conformance['scripts'] = sorted(extrascripts - usedscripts)
    res.append({'tag': '_globalvar', 'variants': ['simple']})
    res.append({'tag': "_phonvar", 'variants': ['alalc97', 'fonipa', 'fonkirsh', 'fonnapa', 'fonupa', 'fonxsamp']})
    res.append(conformance)
    res.append({'tag': "_version", 'api': apiversion, 'date': str(datetime.date.today())})
    if args.jobs == 1:
        for t in sorted(set(lts.values())):
            r = make_record(t, args)
            if r is not None:
                res.append(r[0])
                alllangreg.update(r[1])
    else:
        global proc_record # The func paramter passed of Pool functions must be global.
        def proc_record(t):
            return make_record(t, args)
        pool = Pool(processes=args.jobs) if args.jobs else Pool()
        tempres = pool.imap_unordered(proc_record, sorted(set(lts.values())))
        pool.close()
        pool.join()
        for r in sorted(tempres, key=lambda t: t[0]['full'] if t is not None else ""):
            if r is not None:
                res.append(r[0])
                alllangreg.update(r[1])

    for t in res:
        usedregions.update(getattr(t, 'regions', []))
    possibleregions = set((x for x in regionnames.keys() if len(x) == 2))
    possibleregions.update(('Q' + chr(65+a) for a in range(12, 26)))
    possibleregions.update(('X' + chr(65+a) for a in range(26)))
    conformance['regions'] = sorted(possibleregions - usedregions)

    def mergelines(m):
        return "[" + " ".join(x.strip() for x in m.group(1).split("\n")) + "]"

    if not args.quiet:
        print("Output results")
    output = json.dumps(sorted(res, key=lambda x:x['tag']), sort_keys=True, indent=4, ensure_ascii=False)
    output = "[" + re.sub(r'\[([^\]]+)\]', mergelines, output[1:-1]) + "]\n"
    with open(args.outfile, "w", encoding="utf-8") as fh:
        # use encoding="utf8" (not "utf-8") as a hack around a bug in json: https://stackoverflow.com/a/40777484/10488020
        fh.write(output)
    missing = set(names.keys()) - alllangreg
    missing = set(fromiso639(x, iso639map) for x in missing)
    if len(missing):
        print("Missing language regions ({}): ".format(len(missing)) + " ".join(sorted(missing)))

if __name__ == '__main__':
    set_start_method('fork')
    main()
